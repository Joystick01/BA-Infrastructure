apiVersion: v1
kind: Namespace
metadata:
  name: one-time-jobs

---
apiVersion: batch/v1
kind: Job
metadata:
  name: exporter-job
  namespace: one-time-jobs
spec:
  template:
    spec:
      nodeSelector:
        kubernetes.io/hostname: aks-perf-27904930-vmss000003 # Ersetze dies mit dem Namen des Nodes f√ºr den Prozessor
      containers:
        - name: exporter
          image: ghcr.io/joystick01/kafkaexporter:0.1.4
          env:
            - name: WRITER_TYPE
              value: "DATALAKE"
            - name: DATALAKE_ENDPOINT
              value: "https://sabakaydatalake.dfs.core.windows.net/"
            - name: DATALAKE_SAS_TOKEN
              value: "sv=2022-11-02&ss=bqtf&srt=sco&sp=rwdlacuptf&se=2025-02-01&st=2025-01-01&spr=https&sig=bN15wtx6LqblqA9QZ%2BdffbJ4%2FgDxLyETV9BJZRiJWP0%3D"
            - name: DATALAKE_FILESYSTEM
              value: "fssabakaydatalake"
            - name: DATALAKE_FILE_MESSAGE_COUNT
              value: "161290"
            - name: DATALAKE_PADDING
              value: "4"
            - name: DATALAKE_PREFIX
              value: "low_v3" # Ersetze mit deinem Datalake Prefix
            - name: KAFKA_TOPICS
              value: "ingress,egress"
            - name: BOOTSTRAP_SERVERS_CONFIG
              value: "kafka-broker-0.kafka-cluster.svc.cluster.local:9092,kafka-broker-1.kafka-cluster.svc.cluster.local:9092,kafka-broker-2.kafka-cluster.svc.cluster.local:9092" # Ersetze mit deiner Kafka Bootstrap Servers Adresse
            - name: MAX_POLL_RECORDS_CONFIG
              value: "200000"
      restartPolicy: Never
  backoffLimit: 1