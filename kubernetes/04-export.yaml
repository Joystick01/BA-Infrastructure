apiVersion: v1
kind: Namespace
metadata:
  name: my-one-time-jobs # Optional: Definiere einen Namespace für One-Time Jobs

---
apiVersion: batch/v1
kind: Job
metadata:
  name: exporter-job
  namespace: my-one-time-jobs # Verwende den definierten Namespace
spec:
  template:
    spec:
      nodeSelector:
        kubernetes.io/hostname: "minikube-m03" # Ersetze dies mit dem Namen des Nodes für den Prozessor
      containers:
        - name: exporter
          image: ghcr.io/joystick01/kafkaexporter:0.1.3
          resources:
            requests:
              cpu: "2"
              memory: "8Gi"
            limits:
              cpu: "2"
              memory: "8Gi"
          env:
            - name: WRITER_TYPE
              value: "DATALAKE"
            - name: DATALAKE_ENDPOINT
              value: "<DEIN_DATALAKE_ENDPOINT>" # Ersetze mit deinem Datalake Endpoint
            - name: DATALAKE_SAS_TOKEN
              value: "<DEIN_DATALAKE_SAS_TOKEN>" # Ersetze mit deinem Datalake SAS Token
            - name: DATALAKE_FILESYSTEM
              value: "<DEIN_DATALAKE_FILESYSTEM>" # Ersetze mit deinem Datalake Filesystem
            - name: DATALAKE_FILE_MESSAGE_COUNT
              value: "161290"
            - name: DATALAKE_PADDING
              value: "4"
            - name: DATALAKE_PREFIX
              value: "<DEIN_DATALAKE_PREFIX>" # Ersetze mit deinem Datalake Prefix
            - name: KAFKA_TOPICS
              value: "ingress, egress"
            - name: BOOTSTRAP_SERVERS_CONFIG
              value: "<DEIN_KAFKA_BOOTSTRAP_SERVERS>" # Ersetze mit deiner Kafka Bootstrap Servers Adresse
            - name: MAX_POLL_RECORDS_CONFIG
              value: "1000"
      restartPolicy: Never # Stelle sicher, dass der Pod nicht neu startet, wenn er fertig ist
  backoffLimit: 4 # Optionale Konfiguration für fehlgeschlagene Jobs: Anzahl der Wiederholungsversuche